{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "\n",
    "      \n",
    "class DCGAN_G(nn.Module):\n",
    "    \"\"\" \n",
    "        generator component of WGAN\n",
    "    \"\"\"\n",
    "    def __init__(self, ngf, nz):\n",
    "        super(DCGAN_G, self).__init__()\n",
    "        \n",
    "        self.ngf = ngf\n",
    "        self.nz = nz\n",
    "\n",
    "        kernel = 4\n",
    "        \n",
    "        # input energy shape [batch x 1 x 1 x 1 ] going into convolutional\n",
    "        self.conv1_1 = nn.ConvTranspose3d(1, ngf*4, kernel, 1, 0, bias=False)\n",
    "        # state size [ ngf*4 x 4 x 4 x 4]\n",
    "        \n",
    "        # input noise shape [batch x nz x 1 x 1] going into convolutional\n",
    "        self.conv1_100 = nn.ConvTranspose3d(nz, ngf*4, kernel, 1, 0, bias=False)\n",
    "        # state size [ ngf*4 x 4 x 4 x 4]\n",
    "        \n",
    "        \n",
    "        # outs from first convolutions concatenate state size [ ngf*8 x 4 x 4]\n",
    "        # and going into main convolutional part of Generator\n",
    "        self.main_conv = nn.Sequential(\n",
    "            \n",
    "            nn.ConvTranspose3d(ngf*8, ngf*4, kernel, 2, 1, bias=False),\n",
    "            nn.LayerNorm([8, 8, 8]),\n",
    "            nn.ReLU(),\n",
    "            # state shape [ (ndf*4) x 8 x 8 ]\n",
    "\n",
    "            nn.ConvTranspose3d(ngf*4, ngf*2, kernel, 2, 1, bias=False),\n",
    "            nn.LayerNorm([16, 16, 16]),\n",
    "            nn.ReLU(),\n",
    "            # state shape [ (ndf*2) x 16 x 16 ]\n",
    "\n",
    "            nn.ConvTranspose3d(ngf*2, ngf, kernel, 2, 1, bias=False),\n",
    "            nn.LayerNorm([32, 32, 32]),\n",
    "            nn.ReLU(),\n",
    "            # state shape [ (ndf) x 32 x 32 ]\n",
    "\n",
    "            nn.ConvTranspose3d(ngf, 1, 3, 1, 2, bias=False),\n",
    "            nn.ReLU()\n",
    "            # state shape [ 1 x 30 x 30 x 30 ]\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, energy):\n",
    "        energy_trans = self.conv1_1(energy)\n",
    "        noise_trans = self.conv1_100(noise)\n",
    "        input = torch.cat((energy_trans, noise_trans), 1)\n",
    "        x = self.main_conv(input)\n",
    "        x = x.view(-1, 30, 30, 30)\n",
    "        return x\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('LayerNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "LATENT = 50\n",
    "\n",
    "noise = np.random.uniform(-1, 1, (BATCH_SIZE, LATENT))    \n",
    "noise = torch.from_numpy(noise).float()\n",
    "noise = noise.view(-1, LATENT, 1, 1, 1)    #[BS, nz]  --> [Bs,nz,1,1,1] Needed for Generator\n",
    "noise = noise.to(device)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_labelnp = np.random.uniform(10, 100, (BATCH_SIZE,1,1,1,1))\n",
    "real_label = torch.from_numpy(real_labelnp).float()\n",
    "real_label = real_label.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "aG = DCGAN_G(16, LATENT).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    noisev = noise  # totally freeze G, training D\n",
    "\n",
    "fake_data = aG(noisev, real_label).detach()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 30, 30, 30])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "972208"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in aG.parameters() if p.requires_grad)\n",
    "#aG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "class HDF5Dataset(data.Dataset):\n",
    "    def __init__(self, file_path, train_size, transform=None):\n",
    "        super().__init__()\n",
    "        self.file_path = file_path\n",
    "        self.transform = transform\n",
    "        self.hdf5file = h5py.File(self.file_path, 'r')\n",
    "        \n",
    "        if train_size > self.hdf5file['ecal']['layers'].shape[0]-1:\n",
    "            self.train_size = self.hdf5file['ecal']['layers'].shape[0]-1\n",
    "        else:\n",
    "            self.train_size = train_size\n",
    "            \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.hdf5file['ecal']['layers'][0:self.train_size].shape[0]\n",
    "             \n",
    "    def __getitem__(self, index):\n",
    "        # get data\n",
    "        x = self.get_data(index)\n",
    "        if self.transform:\n",
    "            x = torch.from_numpy(self.transform(x)).float()\n",
    "        else:\n",
    "            x = torch.from_numpy(x).float()\n",
    "        e = torch.from_numpy(self.get_energy(index))\n",
    "        if torch.sum(x) != torch.sum(x): #checks for NANs\n",
    "            return self.__getitem__(int(np.random.rand()*self.__len__()))\n",
    "        else:\n",
    "            return x, e\n",
    "    \n",
    "    def get_data(self, i):\n",
    "        return self.hdf5file['ecal']['layers'][i]\n",
    "    \n",
    "    def get_energy(self, i):\n",
    "        return self.hdf5file['ecal']['energy'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "dataset = HDF5Dataset('/eos/user/e/eneren/run_prod4k/mergedData_prod3k.hdf5', transform=None, train_size=3000)\n",
    "\n",
    "loader_params = {'shuffle': True, 'num_workers': 2}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size = 100, drop_last=True, **loader_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n",
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n",
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n",
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n",
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n",
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n",
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n",
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n",
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n",
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n",
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n",
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n",
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n",
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n",
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n",
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n",
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n",
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n",
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n",
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n",
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n",
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n",
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n",
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n",
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n",
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n",
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n",
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n",
      "torch.Size([100, 30, 30, 30]) torch.Size([100, 1])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (data, energy) in enumerate(train_loader):\n",
    "    print (data.shape, energy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Critic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from criticRes import *\n",
    "#import criticRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n"
     ]
    }
   ],
   "source": [
    "aD = generate_model(18).to(device)\n",
    "for batch_idx, (data, energy) in enumerate(train_loader):\n",
    "    #print (data.shape, energy.shape)\n",
    "    data = data.to(device).unsqueeze(1)  \n",
    "    real_label = energy.to(device)\n",
    "    calo_size = data.size(-1)\n",
    "    \n",
    "    disc_real = aD(data.float(), real_label.float()) \n",
    "    print (disc_real.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2005378"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in aD.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": false,
   "docker_image": "gitlab-registry.cern.ch/ai-ml/kubeflow_images/pytorch-notebook-gpu-1.8.1:v0.6.1-30",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "",
   "snapshot_volumes": false,
   "steps_defaults": [],
   "volume_access_mode": "rwm",
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
